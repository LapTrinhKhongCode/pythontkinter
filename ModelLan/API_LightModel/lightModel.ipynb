{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib\n",
    "\n",
    "def load_data(train_path, test_path, encoder_path=None, scaler_path=None):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    X_train = train_df.iloc[:, :-1].values\n",
    "    y_train = train_df.iloc[:, -1].values\n",
    "    X_test = test_df.iloc[:, :-1].values\n",
    "    y_test = test_df.iloc[:, -1].values\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    # Save the encoder if a path is provided\n",
    "    if encoder_path:\n",
    "        joblib.dump(label_encoder, encoder_path)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Save the scaler if a path is provided\n",
    "    if scaler_path:\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.long),\n",
    "        torch.tensor(X_test, dtype=torch.float32),\n",
    "        torch.tensor(y_test, dtype=torch.long),\n",
    "        len(label_encoder.classes_)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = \"label_encoder.pkl\"\n",
    "scaler_path = \"scaler.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, num_classes = load_data('train_2dist.csv', 'test_2dist.csv',encoder_path=encoder_path, scaler_path=scaler_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),       # Input -> 128\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),               # 128 -> 64\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, num_classes)        # 64 -> Output (num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "model = DeepNet(input_size, num_classes)\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNet(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {100. * correct / total:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += predicted.eq(y_batch).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100. * correct / total:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 1.8346, Accuracy: 47.54%\n",
      "Epoch 2/1000, Loss: 1.0806, Accuracy: 67.01%\n",
      "Epoch 3/1000, Loss: 0.9030, Accuracy: 72.09%\n",
      "Epoch 4/1000, Loss: 0.8099, Accuracy: 75.36%\n",
      "Epoch 5/1000, Loss: 0.7688, Accuracy: 76.83%\n",
      "Epoch 6/1000, Loss: 0.6992, Accuracy: 78.40%\n",
      "Epoch 7/1000, Loss: 0.6605, Accuracy: 80.02%\n",
      "Epoch 8/1000, Loss: 0.6532, Accuracy: 79.81%\n",
      "Epoch 9/1000, Loss: 0.6177, Accuracy: 81.22%\n",
      "Epoch 10/1000, Loss: 0.5640, Accuracy: 82.09%\n",
      "Epoch 11/1000, Loss: 0.5614, Accuracy: 82.48%\n",
      "Epoch 12/1000, Loss: 0.5254, Accuracy: 83.86%\n",
      "Epoch 13/1000, Loss: 0.5348, Accuracy: 83.23%\n",
      "Epoch 14/1000, Loss: 0.5283, Accuracy: 83.68%\n",
      "Epoch 15/1000, Loss: 0.4798, Accuracy: 84.34%\n",
      "Epoch 16/1000, Loss: 0.4950, Accuracy: 84.83%\n",
      "Epoch 17/1000, Loss: 0.4987, Accuracy: 84.89%\n",
      "Epoch 18/1000, Loss: 0.5167, Accuracy: 83.86%\n",
      "Epoch 19/1000, Loss: 0.4666, Accuracy: 84.80%\n",
      "Epoch 20/1000, Loss: 0.4714, Accuracy: 85.73%\n",
      "Epoch 21/1000, Loss: 0.4307, Accuracy: 86.51%\n",
      "Epoch 22/1000, Loss: 0.4459, Accuracy: 85.58%\n",
      "Epoch 23/1000, Loss: 0.4353, Accuracy: 86.39%\n",
      "Epoch 24/1000, Loss: 0.4436, Accuracy: 86.39%\n",
      "Epoch 25/1000, Loss: 0.4320, Accuracy: 85.97%\n",
      "Epoch 26/1000, Loss: 0.4184, Accuracy: 86.99%\n",
      "Epoch 27/1000, Loss: 0.4219, Accuracy: 86.57%\n",
      "Epoch 28/1000, Loss: 0.4131, Accuracy: 86.63%\n",
      "Epoch 29/1000, Loss: 0.4041, Accuracy: 86.42%\n",
      "Epoch 30/1000, Loss: 0.4055, Accuracy: 88.04%\n",
      "Epoch 31/1000, Loss: 0.3989, Accuracy: 86.96%\n",
      "Epoch 32/1000, Loss: 0.3995, Accuracy: 87.23%\n",
      "Epoch 33/1000, Loss: 0.3957, Accuracy: 87.35%\n",
      "Epoch 34/1000, Loss: 0.4114, Accuracy: 86.99%\n",
      "Epoch 35/1000, Loss: 0.3727, Accuracy: 88.49%\n",
      "Epoch 36/1000, Loss: 0.3639, Accuracy: 88.73%\n",
      "Epoch 37/1000, Loss: 0.3767, Accuracy: 88.49%\n",
      "Epoch 38/1000, Loss: 0.3724, Accuracy: 88.43%\n",
      "Epoch 39/1000, Loss: 0.3716, Accuracy: 88.61%\n",
      "Epoch 40/1000, Loss: 0.3516, Accuracy: 89.33%\n",
      "Epoch 41/1000, Loss: 0.3798, Accuracy: 88.67%\n",
      "Epoch 42/1000, Loss: 0.3624, Accuracy: 88.91%\n",
      "Epoch 43/1000, Loss: 0.3932, Accuracy: 87.89%\n",
      "Epoch 44/1000, Loss: 0.3868, Accuracy: 87.71%\n",
      "Epoch 45/1000, Loss: 0.3519, Accuracy: 88.52%\n",
      "Epoch 46/1000, Loss: 0.3323, Accuracy: 89.51%\n",
      "Epoch 47/1000, Loss: 0.3608, Accuracy: 88.55%\n",
      "Epoch 48/1000, Loss: 0.3547, Accuracy: 88.58%\n",
      "Epoch 49/1000, Loss: 0.3474, Accuracy: 89.27%\n",
      "Epoch 50/1000, Loss: 0.3558, Accuracy: 89.00%\n",
      "Epoch 51/1000, Loss: 0.3327, Accuracy: 89.09%\n",
      "Epoch 52/1000, Loss: 0.3405, Accuracy: 89.51%\n",
      "Epoch 53/1000, Loss: 0.3238, Accuracy: 89.69%\n",
      "Epoch 54/1000, Loss: 0.3338, Accuracy: 89.27%\n",
      "Epoch 55/1000, Loss: 0.3278, Accuracy: 89.57%\n",
      "Epoch 56/1000, Loss: 0.3476, Accuracy: 88.49%\n",
      "Epoch 57/1000, Loss: 0.3577, Accuracy: 88.70%\n",
      "Epoch 58/1000, Loss: 0.3363, Accuracy: 89.90%\n",
      "Epoch 59/1000, Loss: 0.3581, Accuracy: 88.91%\n",
      "Epoch 60/1000, Loss: 0.3228, Accuracy: 89.27%\n",
      "Epoch 61/1000, Loss: 0.3055, Accuracy: 90.26%\n",
      "Epoch 62/1000, Loss: 0.3025, Accuracy: 89.93%\n",
      "Epoch 63/1000, Loss: 0.3040, Accuracy: 90.29%\n",
      "Epoch 64/1000, Loss: 0.3377, Accuracy: 89.18%\n",
      "Epoch 65/1000, Loss: 0.3177, Accuracy: 90.47%\n",
      "Epoch 66/1000, Loss: 0.3406, Accuracy: 89.15%\n",
      "Epoch 67/1000, Loss: 0.3185, Accuracy: 90.05%\n",
      "Epoch 68/1000, Loss: 0.3104, Accuracy: 90.05%\n",
      "Epoch 69/1000, Loss: 0.3218, Accuracy: 89.69%\n",
      "Epoch 70/1000, Loss: 0.3134, Accuracy: 89.69%\n",
      "Epoch 71/1000, Loss: 0.3004, Accuracy: 90.26%\n",
      "Epoch 72/1000, Loss: 0.3043, Accuracy: 90.08%\n",
      "Epoch 73/1000, Loss: 0.3079, Accuracy: 90.38%\n",
      "Epoch 74/1000, Loss: 0.3065, Accuracy: 90.29%\n",
      "Epoch 75/1000, Loss: 0.3109, Accuracy: 90.14%\n",
      "Epoch 76/1000, Loss: 0.2855, Accuracy: 90.84%\n",
      "Epoch 77/1000, Loss: 0.3117, Accuracy: 89.63%\n",
      "Epoch 78/1000, Loss: 0.2989, Accuracy: 90.02%\n",
      "Epoch 79/1000, Loss: 0.2668, Accuracy: 91.02%\n",
      "Epoch 80/1000, Loss: 0.2829, Accuracy: 91.23%\n",
      "Epoch 81/1000, Loss: 0.3017, Accuracy: 90.05%\n",
      "Epoch 82/1000, Loss: 0.3263, Accuracy: 89.09%\n",
      "Epoch 83/1000, Loss: 0.3082, Accuracy: 90.20%\n",
      "Epoch 84/1000, Loss: 0.3085, Accuracy: 90.41%\n",
      "Epoch 85/1000, Loss: 0.2928, Accuracy: 90.66%\n",
      "Epoch 86/1000, Loss: 0.3261, Accuracy: 89.72%\n",
      "Epoch 87/1000, Loss: 0.3061, Accuracy: 90.14%\n",
      "Epoch 88/1000, Loss: 0.2926, Accuracy: 90.53%\n",
      "Epoch 89/1000, Loss: 0.2865, Accuracy: 90.87%\n",
      "Epoch 90/1000, Loss: 0.2590, Accuracy: 91.74%\n",
      "Epoch 91/1000, Loss: 0.2841, Accuracy: 90.75%\n",
      "Epoch 92/1000, Loss: 0.2848, Accuracy: 90.32%\n",
      "Epoch 93/1000, Loss: 0.2825, Accuracy: 91.38%\n",
      "Epoch 94/1000, Loss: 0.2774, Accuracy: 90.96%\n",
      "Epoch 95/1000, Loss: 0.2649, Accuracy: 91.71%\n",
      "Epoch 96/1000, Loss: 0.2809, Accuracy: 90.93%\n",
      "Epoch 97/1000, Loss: 0.2660, Accuracy: 91.29%\n",
      "Epoch 98/1000, Loss: 0.2548, Accuracy: 91.59%\n",
      "Epoch 99/1000, Loss: 0.2630, Accuracy: 91.47%\n",
      "Epoch 100/1000, Loss: 0.2858, Accuracy: 91.14%\n",
      "Epoch 101/1000, Loss: 0.2879, Accuracy: 90.96%\n",
      "Epoch 102/1000, Loss: 0.2940, Accuracy: 90.69%\n",
      "Epoch 103/1000, Loss: 0.3008, Accuracy: 91.05%\n",
      "Epoch 104/1000, Loss: 0.2612, Accuracy: 91.65%\n",
      "Epoch 105/1000, Loss: 0.2861, Accuracy: 90.84%\n",
      "Epoch 106/1000, Loss: 0.2697, Accuracy: 91.29%\n",
      "Epoch 107/1000, Loss: 0.2955, Accuracy: 91.08%\n",
      "Epoch 108/1000, Loss: 0.2716, Accuracy: 91.38%\n",
      "Epoch 109/1000, Loss: 0.2700, Accuracy: 91.41%\n",
      "Epoch 110/1000, Loss: 0.2640, Accuracy: 91.05%\n",
      "Epoch 111/1000, Loss: 0.2580, Accuracy: 91.68%\n",
      "Epoch 112/1000, Loss: 0.2682, Accuracy: 91.05%\n",
      "Epoch 113/1000, Loss: 0.2704, Accuracy: 91.71%\n",
      "Epoch 114/1000, Loss: 0.2664, Accuracy: 91.59%\n",
      "Epoch 115/1000, Loss: 0.2745, Accuracy: 90.96%\n",
      "Epoch 116/1000, Loss: 0.2730, Accuracy: 91.23%\n",
      "Epoch 117/1000, Loss: 0.2570, Accuracy: 91.83%\n",
      "Epoch 118/1000, Loss: 0.2821, Accuracy: 91.23%\n",
      "Epoch 119/1000, Loss: 0.2565, Accuracy: 91.38%\n",
      "Epoch 120/1000, Loss: 0.2722, Accuracy: 91.17%\n",
      "Epoch 121/1000, Loss: 0.2653, Accuracy: 91.44%\n",
      "Epoch 122/1000, Loss: 0.2618, Accuracy: 91.32%\n",
      "Epoch 123/1000, Loss: 0.2733, Accuracy: 91.26%\n",
      "Epoch 124/1000, Loss: 0.2616, Accuracy: 91.20%\n",
      "Epoch 125/1000, Loss: 0.2595, Accuracy: 91.92%\n",
      "Epoch 126/1000, Loss: 0.2392, Accuracy: 92.13%\n",
      "Epoch 127/1000, Loss: 0.2405, Accuracy: 91.47%\n",
      "Epoch 128/1000, Loss: 0.2687, Accuracy: 91.77%\n",
      "Epoch 129/1000, Loss: 0.2385, Accuracy: 91.98%\n",
      "Epoch 130/1000, Loss: 0.2687, Accuracy: 91.62%\n",
      "Epoch 131/1000, Loss: 0.2440, Accuracy: 92.28%\n",
      "Epoch 132/1000, Loss: 0.2858, Accuracy: 90.81%\n",
      "Epoch 133/1000, Loss: 0.2514, Accuracy: 91.59%\n",
      "Epoch 134/1000, Loss: 0.2667, Accuracy: 91.56%\n",
      "Epoch 135/1000, Loss: 0.2490, Accuracy: 91.95%\n",
      "Epoch 136/1000, Loss: 0.2529, Accuracy: 91.89%\n",
      "Epoch 137/1000, Loss: 0.2351, Accuracy: 92.49%\n",
      "Epoch 138/1000, Loss: 0.2625, Accuracy: 91.65%\n",
      "Epoch 139/1000, Loss: 0.2667, Accuracy: 91.62%\n",
      "Epoch 140/1000, Loss: 0.2508, Accuracy: 91.80%\n",
      "Epoch 141/1000, Loss: 0.2769, Accuracy: 91.05%\n",
      "Epoch 142/1000, Loss: 0.2453, Accuracy: 92.22%\n",
      "Epoch 143/1000, Loss: 0.2467, Accuracy: 92.31%\n",
      "Epoch 144/1000, Loss: 0.2454, Accuracy: 92.55%\n",
      "Epoch 145/1000, Loss: 0.2536, Accuracy: 91.71%\n",
      "Epoch 146/1000, Loss: 0.2622, Accuracy: 91.47%\n",
      "Epoch 147/1000, Loss: 0.2812, Accuracy: 91.11%\n",
      "Epoch 148/1000, Loss: 0.2473, Accuracy: 92.10%\n",
      "Epoch 149/1000, Loss: 0.2452, Accuracy: 92.46%\n",
      "Epoch 150/1000, Loss: 0.2340, Accuracy: 92.61%\n",
      "Epoch 151/1000, Loss: 0.2567, Accuracy: 91.77%\n",
      "Epoch 152/1000, Loss: 0.2672, Accuracy: 91.59%\n",
      "Epoch 153/1000, Loss: 0.2563, Accuracy: 92.04%\n",
      "Epoch 154/1000, Loss: 0.2771, Accuracy: 91.29%\n",
      "Epoch 155/1000, Loss: 0.2571, Accuracy: 92.04%\n",
      "Epoch 156/1000, Loss: 0.2400, Accuracy: 92.40%\n",
      "Epoch 157/1000, Loss: 0.2233, Accuracy: 92.91%\n",
      "Epoch 158/1000, Loss: 0.2687, Accuracy: 91.62%\n",
      "Epoch 159/1000, Loss: 0.2260, Accuracy: 92.82%\n",
      "Epoch 160/1000, Loss: 0.2383, Accuracy: 92.37%\n",
      "Epoch 161/1000, Loss: 0.2336, Accuracy: 92.49%\n",
      "Epoch 162/1000, Loss: 0.2171, Accuracy: 93.24%\n",
      "Epoch 163/1000, Loss: 0.2467, Accuracy: 92.46%\n",
      "Epoch 164/1000, Loss: 0.2260, Accuracy: 92.46%\n",
      "Epoch 165/1000, Loss: 0.2347, Accuracy: 91.65%\n",
      "Epoch 166/1000, Loss: 0.2513, Accuracy: 92.31%\n",
      "Epoch 167/1000, Loss: 0.2330, Accuracy: 92.31%\n",
      "Epoch 168/1000, Loss: 0.2257, Accuracy: 92.64%\n",
      "Epoch 169/1000, Loss: 0.2266, Accuracy: 92.76%\n",
      "Epoch 170/1000, Loss: 0.2378, Accuracy: 92.13%\n",
      "Epoch 171/1000, Loss: 0.2453, Accuracy: 92.10%\n",
      "Epoch 172/1000, Loss: 0.2353, Accuracy: 92.73%\n",
      "Epoch 173/1000, Loss: 0.2230, Accuracy: 92.46%\n",
      "Epoch 174/1000, Loss: 0.2306, Accuracy: 92.22%\n",
      "Epoch 175/1000, Loss: 0.2572, Accuracy: 91.89%\n",
      "Epoch 176/1000, Loss: 0.2262, Accuracy: 92.61%\n",
      "Epoch 177/1000, Loss: 0.2114, Accuracy: 92.82%\n",
      "Epoch 178/1000, Loss: 0.2347, Accuracy: 92.46%\n",
      "Epoch 179/1000, Loss: 0.2294, Accuracy: 92.49%\n",
      "Epoch 180/1000, Loss: 0.2245, Accuracy: 92.79%\n",
      "Epoch 181/1000, Loss: 0.2315, Accuracy: 92.04%\n",
      "Epoch 182/1000, Loss: 0.2261, Accuracy: 92.52%\n",
      "Epoch 183/1000, Loss: 0.2162, Accuracy: 92.52%\n",
      "Epoch 184/1000, Loss: 0.2238, Accuracy: 92.88%\n",
      "Epoch 185/1000, Loss: 0.2250, Accuracy: 92.40%\n",
      "Epoch 186/1000, Loss: 0.2322, Accuracy: 92.52%\n",
      "Epoch 187/1000, Loss: 0.2215, Accuracy: 92.40%\n",
      "Epoch 188/1000, Loss: 0.2468, Accuracy: 92.31%\n",
      "Epoch 189/1000, Loss: 0.2405, Accuracy: 92.19%\n",
      "Epoch 190/1000, Loss: 0.2311, Accuracy: 92.07%\n",
      "Epoch 191/1000, Loss: 0.2312, Accuracy: 92.16%\n",
      "Epoch 192/1000, Loss: 0.2246, Accuracy: 92.91%\n",
      "Epoch 193/1000, Loss: 0.2439, Accuracy: 92.82%\n",
      "Epoch 194/1000, Loss: 0.2378, Accuracy: 92.70%\n",
      "Epoch 195/1000, Loss: 0.2164, Accuracy: 92.97%\n",
      "Epoch 196/1000, Loss: 0.2270, Accuracy: 92.28%\n",
      "Epoch 197/1000, Loss: 0.2200, Accuracy: 92.88%\n",
      "Epoch 198/1000, Loss: 0.2175, Accuracy: 92.88%\n",
      "Epoch 199/1000, Loss: 0.2514, Accuracy: 92.31%\n",
      "Epoch 200/1000, Loss: 0.2255, Accuracy: 92.73%\n",
      "Epoch 201/1000, Loss: 0.2446, Accuracy: 92.01%\n",
      "Epoch 202/1000, Loss: 0.2200, Accuracy: 92.70%\n",
      "Epoch 203/1000, Loss: 0.2009, Accuracy: 92.97%\n",
      "Epoch 204/1000, Loss: 0.2154, Accuracy: 93.09%\n",
      "Epoch 205/1000, Loss: 0.2333, Accuracy: 92.46%\n",
      "Epoch 206/1000, Loss: 0.2365, Accuracy: 92.37%\n",
      "Epoch 207/1000, Loss: 0.2169, Accuracy: 92.76%\n",
      "Epoch 208/1000, Loss: 0.2348, Accuracy: 92.76%\n",
      "Epoch 209/1000, Loss: 0.2350, Accuracy: 92.49%\n",
      "Epoch 210/1000, Loss: 0.2188, Accuracy: 92.79%\n",
      "Epoch 211/1000, Loss: 0.2248, Accuracy: 92.49%\n",
      "Epoch 212/1000, Loss: 0.2196, Accuracy: 92.58%\n",
      "Epoch 213/1000, Loss: 0.2341, Accuracy: 92.73%\n",
      "Epoch 214/1000, Loss: 0.2261, Accuracy: 93.09%\n",
      "Epoch 215/1000, Loss: 0.2337, Accuracy: 92.64%\n",
      "Epoch 216/1000, Loss: 0.2224, Accuracy: 93.30%\n",
      "Epoch 217/1000, Loss: 0.2162, Accuracy: 93.36%\n",
      "Epoch 218/1000, Loss: 0.2420, Accuracy: 92.04%\n",
      "Epoch 219/1000, Loss: 0.2418, Accuracy: 92.04%\n",
      "Epoch 220/1000, Loss: 0.2298, Accuracy: 92.13%\n",
      "Epoch 221/1000, Loss: 0.2218, Accuracy: 92.55%\n",
      "Epoch 222/1000, Loss: 0.2052, Accuracy: 93.03%\n",
      "Epoch 223/1000, Loss: 0.2211, Accuracy: 92.67%\n",
      "Epoch 224/1000, Loss: 0.1920, Accuracy: 93.54%\n",
      "Epoch 225/1000, Loss: 0.2288, Accuracy: 93.18%\n",
      "Epoch 226/1000, Loss: 0.2305, Accuracy: 92.70%\n",
      "Epoch 227/1000, Loss: 0.2279, Accuracy: 93.00%\n",
      "Epoch 228/1000, Loss: 0.2371, Accuracy: 92.64%\n",
      "Epoch 229/1000, Loss: 0.2281, Accuracy: 93.03%\n",
      "Epoch 230/1000, Loss: 0.2325, Accuracy: 92.25%\n",
      "Epoch 231/1000, Loss: 0.2201, Accuracy: 93.00%\n",
      "Epoch 232/1000, Loss: 0.2146, Accuracy: 93.09%\n",
      "Epoch 233/1000, Loss: 0.2012, Accuracy: 93.45%\n",
      "Epoch 234/1000, Loss: 0.2160, Accuracy: 93.12%\n",
      "Epoch 235/1000, Loss: 0.1984, Accuracy: 93.24%\n",
      "Epoch 236/1000, Loss: 0.2280, Accuracy: 92.67%\n",
      "Epoch 237/1000, Loss: 0.2156, Accuracy: 92.73%\n",
      "Epoch 238/1000, Loss: 0.2095, Accuracy: 93.12%\n",
      "Epoch 239/1000, Loss: 0.2301, Accuracy: 92.34%\n",
      "Epoch 240/1000, Loss: 0.2029, Accuracy: 93.57%\n",
      "Epoch 241/1000, Loss: 0.2171, Accuracy: 92.58%\n",
      "Epoch 242/1000, Loss: 0.2392, Accuracy: 92.64%\n",
      "Epoch 243/1000, Loss: 0.2158, Accuracy: 92.82%\n",
      "Epoch 244/1000, Loss: 0.2091, Accuracy: 93.51%\n",
      "Epoch 245/1000, Loss: 0.2050, Accuracy: 93.30%\n",
      "Epoch 246/1000, Loss: 0.2142, Accuracy: 92.73%\n",
      "Epoch 247/1000, Loss: 0.2122, Accuracy: 93.33%\n",
      "Epoch 248/1000, Loss: 0.1981, Accuracy: 93.45%\n",
      "Epoch 249/1000, Loss: 0.2399, Accuracy: 92.25%\n",
      "Epoch 250/1000, Loss: 0.2200, Accuracy: 92.91%\n",
      "Epoch 251/1000, Loss: 0.2221, Accuracy: 93.03%\n",
      "Epoch 252/1000, Loss: 0.2161, Accuracy: 93.09%\n",
      "Epoch 253/1000, Loss: 0.2116, Accuracy: 92.61%\n",
      "Epoch 254/1000, Loss: 0.2042, Accuracy: 93.30%\n",
      "Epoch 255/1000, Loss: 0.2006, Accuracy: 93.48%\n",
      "Epoch 256/1000, Loss: 0.2122, Accuracy: 93.21%\n",
      "Epoch 257/1000, Loss: 0.2104, Accuracy: 93.15%\n",
      "Epoch 258/1000, Loss: 0.2204, Accuracy: 93.27%\n",
      "Epoch 259/1000, Loss: 0.2140, Accuracy: 92.76%\n",
      "Epoch 260/1000, Loss: 0.1921, Accuracy: 93.60%\n",
      "Epoch 261/1000, Loss: 0.2015, Accuracy: 93.63%\n",
      "Epoch 262/1000, Loss: 0.1982, Accuracy: 93.36%\n",
      "Epoch 263/1000, Loss: 0.2163, Accuracy: 92.97%\n",
      "Epoch 264/1000, Loss: 0.2004, Accuracy: 93.21%\n",
      "Epoch 265/1000, Loss: 0.2135, Accuracy: 92.88%\n",
      "Epoch 266/1000, Loss: 0.1882, Accuracy: 93.96%\n",
      "Epoch 267/1000, Loss: 0.2128, Accuracy: 93.39%\n",
      "Epoch 268/1000, Loss: 0.2186, Accuracy: 92.79%\n",
      "Epoch 269/1000, Loss: 0.2384, Accuracy: 92.34%\n",
      "Epoch 270/1000, Loss: 0.2388, Accuracy: 92.40%\n",
      "Epoch 271/1000, Loss: 0.2093, Accuracy: 93.18%\n",
      "Epoch 272/1000, Loss: 0.2229, Accuracy: 92.91%\n",
      "Epoch 273/1000, Loss: 0.2154, Accuracy: 93.00%\n",
      "Epoch 274/1000, Loss: 0.2120, Accuracy: 93.36%\n",
      "Epoch 275/1000, Loss: 0.1901, Accuracy: 93.66%\n",
      "Epoch 276/1000, Loss: 0.1901, Accuracy: 93.81%\n",
      "Epoch 277/1000, Loss: 0.2179, Accuracy: 93.33%\n",
      "Epoch 278/1000, Loss: 0.2169, Accuracy: 93.30%\n",
      "Epoch 279/1000, Loss: 0.1967, Accuracy: 93.66%\n",
      "Epoch 280/1000, Loss: 0.2019, Accuracy: 93.60%\n",
      "Epoch 281/1000, Loss: 0.1886, Accuracy: 93.99%\n",
      "Epoch 282/1000, Loss: 0.1950, Accuracy: 93.42%\n",
      "Epoch 283/1000, Loss: 0.1931, Accuracy: 93.45%\n",
      "Epoch 284/1000, Loss: 0.2151, Accuracy: 93.12%\n",
      "Epoch 285/1000, Loss: 0.2184, Accuracy: 92.43%\n",
      "Epoch 286/1000, Loss: 0.2161, Accuracy: 93.03%\n",
      "Epoch 287/1000, Loss: 0.2051, Accuracy: 93.60%\n",
      "Epoch 288/1000, Loss: 0.2056, Accuracy: 93.69%\n",
      "Epoch 289/1000, Loss: 0.2221, Accuracy: 92.58%\n",
      "Epoch 290/1000, Loss: 0.1969, Accuracy: 93.60%\n",
      "Epoch 291/1000, Loss: 0.1986, Accuracy: 93.06%\n",
      "Epoch 292/1000, Loss: 0.2281, Accuracy: 92.46%\n",
      "Epoch 293/1000, Loss: 0.2126, Accuracy: 93.39%\n",
      "Epoch 294/1000, Loss: 0.1901, Accuracy: 93.84%\n",
      "Epoch 295/1000, Loss: 0.1918, Accuracy: 93.84%\n",
      "Epoch 296/1000, Loss: 0.1965, Accuracy: 93.72%\n",
      "Epoch 297/1000, Loss: 0.1890, Accuracy: 93.69%\n",
      "Epoch 298/1000, Loss: 0.2143, Accuracy: 93.51%\n",
      "Epoch 299/1000, Loss: 0.2120, Accuracy: 93.12%\n",
      "Epoch 300/1000, Loss: 0.1923, Accuracy: 93.84%\n",
      "Epoch 301/1000, Loss: 0.1938, Accuracy: 93.75%\n",
      "Epoch 302/1000, Loss: 0.1901, Accuracy: 93.63%\n",
      "Epoch 303/1000, Loss: 0.1832, Accuracy: 93.72%\n",
      "Epoch 304/1000, Loss: 0.2150, Accuracy: 93.09%\n",
      "Epoch 305/1000, Loss: 0.1742, Accuracy: 94.32%\n",
      "Epoch 306/1000, Loss: 0.2111, Accuracy: 92.97%\n",
      "Epoch 307/1000, Loss: 0.2097, Accuracy: 93.24%\n",
      "Epoch 308/1000, Loss: 0.2193, Accuracy: 92.58%\n",
      "Epoch 309/1000, Loss: 0.2084, Accuracy: 93.24%\n",
      "Epoch 310/1000, Loss: 0.2028, Accuracy: 93.78%\n",
      "Epoch 311/1000, Loss: 0.1892, Accuracy: 93.63%\n",
      "Epoch 312/1000, Loss: 0.1885, Accuracy: 94.08%\n",
      "Epoch 313/1000, Loss: 0.2111, Accuracy: 93.54%\n",
      "Epoch 314/1000, Loss: 0.1916, Accuracy: 94.11%\n",
      "Epoch 315/1000, Loss: 0.1959, Accuracy: 93.75%\n",
      "Epoch 316/1000, Loss: 0.1999, Accuracy: 93.84%\n",
      "Epoch 317/1000, Loss: 0.1822, Accuracy: 93.69%\n",
      "Epoch 318/1000, Loss: 0.2003, Accuracy: 93.60%\n",
      "Epoch 319/1000, Loss: 0.2000, Accuracy: 93.66%\n",
      "Epoch 320/1000, Loss: 0.1914, Accuracy: 93.66%\n",
      "Epoch 321/1000, Loss: 0.1984, Accuracy: 93.78%\n",
      "Epoch 322/1000, Loss: 0.1855, Accuracy: 93.66%\n",
      "Epoch 323/1000, Loss: 0.1953, Accuracy: 93.90%\n",
      "Epoch 324/1000, Loss: 0.2120, Accuracy: 93.15%\n",
      "Epoch 325/1000, Loss: 0.2005, Accuracy: 93.78%\n",
      "Epoch 326/1000, Loss: 0.2165, Accuracy: 93.48%\n",
      "Epoch 327/1000, Loss: 0.2060, Accuracy: 93.45%\n",
      "Epoch 328/1000, Loss: 0.2004, Accuracy: 93.33%\n",
      "Epoch 329/1000, Loss: 0.1938, Accuracy: 93.39%\n",
      "Epoch 330/1000, Loss: 0.1949, Accuracy: 93.66%\n",
      "Epoch 331/1000, Loss: 0.2057, Accuracy: 93.48%\n",
      "Epoch 332/1000, Loss: 0.1846, Accuracy: 93.60%\n",
      "Epoch 333/1000, Loss: 0.2006, Accuracy: 93.72%\n",
      "Epoch 334/1000, Loss: 0.2129, Accuracy: 93.33%\n",
      "Epoch 335/1000, Loss: 0.1828, Accuracy: 93.63%\n",
      "Epoch 336/1000, Loss: 0.1834, Accuracy: 93.96%\n",
      "Epoch 337/1000, Loss: 0.1815, Accuracy: 93.78%\n",
      "Epoch 338/1000, Loss: 0.2057, Accuracy: 93.27%\n",
      "Epoch 339/1000, Loss: 0.1976, Accuracy: 93.36%\n",
      "Epoch 340/1000, Loss: 0.2079, Accuracy: 93.18%\n",
      "Epoch 341/1000, Loss: 0.2019, Accuracy: 93.42%\n",
      "Epoch 342/1000, Loss: 0.1810, Accuracy: 94.17%\n",
      "Epoch 343/1000, Loss: 0.2077, Accuracy: 93.42%\n",
      "Epoch 344/1000, Loss: 0.1889, Accuracy: 93.87%\n",
      "Epoch 345/1000, Loss: 0.1898, Accuracy: 93.60%\n",
      "Epoch 346/1000, Loss: 0.2033, Accuracy: 93.21%\n",
      "Epoch 347/1000, Loss: 0.1988, Accuracy: 93.78%\n",
      "Epoch 348/1000, Loss: 0.1968, Accuracy: 93.51%\n",
      "Epoch 349/1000, Loss: 0.1918, Accuracy: 94.11%\n",
      "Epoch 350/1000, Loss: 0.2046, Accuracy: 93.54%\n",
      "Epoch 351/1000, Loss: 0.2021, Accuracy: 93.48%\n",
      "Epoch 352/1000, Loss: 0.2051, Accuracy: 92.91%\n",
      "Epoch 353/1000, Loss: 0.1825, Accuracy: 93.81%\n",
      "Epoch 354/1000, Loss: 0.1844, Accuracy: 93.75%\n",
      "Epoch 355/1000, Loss: 0.2046, Accuracy: 93.63%\n",
      "Epoch 356/1000, Loss: 0.2016, Accuracy: 93.51%\n",
      "Epoch 357/1000, Loss: 0.2066, Accuracy: 93.18%\n",
      "Epoch 358/1000, Loss: 0.2014, Accuracy: 93.45%\n",
      "Epoch 359/1000, Loss: 0.1936, Accuracy: 93.48%\n",
      "Epoch 360/1000, Loss: 0.2073, Accuracy: 93.48%\n",
      "Epoch 361/1000, Loss: 0.1781, Accuracy: 93.84%\n",
      "Epoch 362/1000, Loss: 0.1834, Accuracy: 93.75%\n",
      "Epoch 363/1000, Loss: 0.1958, Accuracy: 94.08%\n",
      "Epoch 364/1000, Loss: 0.2026, Accuracy: 93.78%\n",
      "Epoch 365/1000, Loss: 0.1912, Accuracy: 93.42%\n",
      "Epoch 366/1000, Loss: 0.1920, Accuracy: 93.90%\n",
      "Epoch 367/1000, Loss: 0.1826, Accuracy: 93.63%\n",
      "Epoch 368/1000, Loss: 0.1917, Accuracy: 93.90%\n",
      "Epoch 369/1000, Loss: 0.1945, Accuracy: 93.36%\n",
      "Epoch 370/1000, Loss: 0.1888, Accuracy: 94.05%\n",
      "Epoch 371/1000, Loss: 0.1915, Accuracy: 93.72%\n",
      "Epoch 372/1000, Loss: 0.1912, Accuracy: 93.75%\n",
      "Epoch 373/1000, Loss: 0.1734, Accuracy: 93.96%\n",
      "Epoch 374/1000, Loss: 0.1994, Accuracy: 93.99%\n",
      "Epoch 375/1000, Loss: 0.1806, Accuracy: 94.26%\n",
      "Epoch 376/1000, Loss: 0.1871, Accuracy: 93.30%\n",
      "Epoch 377/1000, Loss: 0.1763, Accuracy: 93.99%\n",
      "Epoch 378/1000, Loss: 0.1906, Accuracy: 93.96%\n",
      "Epoch 379/1000, Loss: 0.1864, Accuracy: 93.99%\n",
      "Epoch 380/1000, Loss: 0.1972, Accuracy: 93.54%\n",
      "Epoch 381/1000, Loss: 0.1888, Accuracy: 93.45%\n",
      "Epoch 382/1000, Loss: 0.1946, Accuracy: 93.54%\n",
      "Epoch 383/1000, Loss: 0.1891, Accuracy: 93.66%\n",
      "Epoch 384/1000, Loss: 0.1993, Accuracy: 93.69%\n",
      "Epoch 385/1000, Loss: 0.1869, Accuracy: 93.84%\n",
      "Epoch 386/1000, Loss: 0.2035, Accuracy: 93.54%\n",
      "Epoch 387/1000, Loss: 0.2016, Accuracy: 93.69%\n",
      "Epoch 388/1000, Loss: 0.1778, Accuracy: 94.32%\n",
      "Epoch 389/1000, Loss: 0.1937, Accuracy: 94.05%\n",
      "Epoch 390/1000, Loss: 0.1978, Accuracy: 93.45%\n",
      "Epoch 391/1000, Loss: 0.1711, Accuracy: 94.26%\n",
      "Epoch 392/1000, Loss: 0.1973, Accuracy: 93.87%\n",
      "Epoch 393/1000, Loss: 0.1801, Accuracy: 94.29%\n",
      "Epoch 394/1000, Loss: 0.1971, Accuracy: 93.60%\n",
      "Epoch 395/1000, Loss: 0.2052, Accuracy: 93.54%\n",
      "Epoch 396/1000, Loss: 0.2007, Accuracy: 93.66%\n",
      "Epoch 397/1000, Loss: 0.1887, Accuracy: 93.69%\n",
      "Epoch 398/1000, Loss: 0.1859, Accuracy: 94.26%\n",
      "Epoch 399/1000, Loss: 0.1860, Accuracy: 94.17%\n",
      "Epoch 400/1000, Loss: 0.1734, Accuracy: 94.11%\n",
      "Epoch 401/1000, Loss: 0.1835, Accuracy: 94.05%\n",
      "Epoch 402/1000, Loss: 0.1944, Accuracy: 93.81%\n",
      "Epoch 403/1000, Loss: 0.1817, Accuracy: 94.26%\n",
      "Epoch 404/1000, Loss: 0.1975, Accuracy: 93.75%\n",
      "Epoch 405/1000, Loss: 0.2080, Accuracy: 93.09%\n",
      "Epoch 406/1000, Loss: 0.1936, Accuracy: 94.05%\n",
      "Epoch 407/1000, Loss: 0.1880, Accuracy: 94.23%\n",
      "Epoch 408/1000, Loss: 0.1961, Accuracy: 93.81%\n",
      "Epoch 409/1000, Loss: 0.1900, Accuracy: 94.14%\n",
      "Epoch 410/1000, Loss: 0.1970, Accuracy: 93.06%\n",
      "Epoch 411/1000, Loss: 0.1860, Accuracy: 93.51%\n",
      "Epoch 412/1000, Loss: 0.1953, Accuracy: 93.90%\n",
      "Epoch 413/1000, Loss: 0.1773, Accuracy: 94.47%\n",
      "Epoch 414/1000, Loss: 0.1928, Accuracy: 94.23%\n",
      "Epoch 415/1000, Loss: 0.1928, Accuracy: 93.72%\n",
      "Epoch 416/1000, Loss: 0.1768, Accuracy: 94.59%\n",
      "Epoch 417/1000, Loss: 0.1830, Accuracy: 94.35%\n",
      "Epoch 418/1000, Loss: 0.1831, Accuracy: 94.11%\n",
      "Epoch 419/1000, Loss: 0.2102, Accuracy: 93.57%\n",
      "Epoch 420/1000, Loss: 0.1824, Accuracy: 94.29%\n",
      "Epoch 421/1000, Loss: 0.1953, Accuracy: 93.66%\n",
      "Epoch 422/1000, Loss: 0.1957, Accuracy: 93.24%\n",
      "Epoch 423/1000, Loss: 0.1876, Accuracy: 93.69%\n",
      "Epoch 424/1000, Loss: 0.1825, Accuracy: 94.23%\n",
      "Epoch 425/1000, Loss: 0.1953, Accuracy: 93.57%\n",
      "Epoch 426/1000, Loss: 0.1851, Accuracy: 94.14%\n",
      "Epoch 427/1000, Loss: 0.1733, Accuracy: 94.26%\n",
      "Epoch 428/1000, Loss: 0.1918, Accuracy: 93.75%\n",
      "Epoch 429/1000, Loss: 0.1650, Accuracy: 94.56%\n",
      "Epoch 430/1000, Loss: 0.1857, Accuracy: 93.90%\n",
      "Epoch 431/1000, Loss: 0.1953, Accuracy: 93.51%\n",
      "Epoch 432/1000, Loss: 0.1810, Accuracy: 93.96%\n",
      "Epoch 433/1000, Loss: 0.2034, Accuracy: 93.57%\n",
      "Epoch 434/1000, Loss: 0.1769, Accuracy: 93.99%\n",
      "Epoch 435/1000, Loss: 0.1979, Accuracy: 93.57%\n",
      "Epoch 436/1000, Loss: 0.1902, Accuracy: 93.93%\n",
      "Epoch 437/1000, Loss: 0.2032, Accuracy: 93.69%\n",
      "Epoch 438/1000, Loss: 0.1907, Accuracy: 93.48%\n",
      "Epoch 439/1000, Loss: 0.1943, Accuracy: 93.78%\n",
      "Epoch 440/1000, Loss: 0.1882, Accuracy: 93.90%\n",
      "Epoch 441/1000, Loss: 0.1777, Accuracy: 94.11%\n",
      "Epoch 442/1000, Loss: 0.1702, Accuracy: 94.38%\n",
      "Epoch 443/1000, Loss: 0.1981, Accuracy: 93.75%\n",
      "Epoch 444/1000, Loss: 0.1954, Accuracy: 93.57%\n",
      "Epoch 445/1000, Loss: 0.1543, Accuracy: 95.10%\n",
      "Epoch 446/1000, Loss: 0.1762, Accuracy: 94.26%\n",
      "Epoch 447/1000, Loss: 0.1814, Accuracy: 93.81%\n",
      "Epoch 448/1000, Loss: 0.1835, Accuracy: 93.84%\n",
      "Epoch 449/1000, Loss: 0.1813, Accuracy: 93.96%\n",
      "Epoch 450/1000, Loss: 0.1785, Accuracy: 94.05%\n",
      "Epoch 451/1000, Loss: 0.1625, Accuracy: 94.74%\n",
      "Epoch 452/1000, Loss: 0.1741, Accuracy: 94.47%\n",
      "Epoch 453/1000, Loss: 0.1814, Accuracy: 94.17%\n",
      "Epoch 454/1000, Loss: 0.2153, Accuracy: 93.42%\n",
      "Epoch 455/1000, Loss: 0.1917, Accuracy: 93.75%\n",
      "Epoch 456/1000, Loss: 0.2049, Accuracy: 93.51%\n",
      "Epoch 457/1000, Loss: 0.1816, Accuracy: 94.05%\n",
      "Epoch 458/1000, Loss: 0.1897, Accuracy: 93.84%\n",
      "Epoch 459/1000, Loss: 0.1585, Accuracy: 94.80%\n",
      "Epoch 460/1000, Loss: 0.1854, Accuracy: 94.14%\n",
      "Epoch 461/1000, Loss: 0.1789, Accuracy: 94.20%\n",
      "Epoch 462/1000, Loss: 0.1845, Accuracy: 93.84%\n",
      "Epoch 463/1000, Loss: 0.1675, Accuracy: 94.53%\n",
      "Epoch 464/1000, Loss: 0.1717, Accuracy: 94.23%\n",
      "Epoch 465/1000, Loss: 0.1929, Accuracy: 93.99%\n",
      "Epoch 466/1000, Loss: 0.2054, Accuracy: 93.60%\n",
      "Epoch 467/1000, Loss: 0.1796, Accuracy: 94.32%\n",
      "Epoch 468/1000, Loss: 0.1844, Accuracy: 94.20%\n",
      "Epoch 469/1000, Loss: 0.1863, Accuracy: 93.96%\n",
      "Epoch 470/1000, Loss: 0.1862, Accuracy: 94.08%\n",
      "Epoch 471/1000, Loss: 0.1718, Accuracy: 94.23%\n",
      "Epoch 472/1000, Loss: 0.2047, Accuracy: 93.63%\n",
      "Epoch 473/1000, Loss: 0.1835, Accuracy: 93.81%\n",
      "Epoch 474/1000, Loss: 0.1759, Accuracy: 94.41%\n",
      "Epoch 475/1000, Loss: 0.1849, Accuracy: 93.87%\n",
      "Epoch 476/1000, Loss: 0.1913, Accuracy: 94.20%\n",
      "Epoch 477/1000, Loss: 0.1970, Accuracy: 94.08%\n",
      "Epoch 478/1000, Loss: 0.1934, Accuracy: 93.93%\n",
      "Epoch 479/1000, Loss: 0.1825, Accuracy: 93.72%\n",
      "Epoch 480/1000, Loss: 0.1698, Accuracy: 94.11%\n",
      "Epoch 481/1000, Loss: 0.1655, Accuracy: 94.71%\n",
      "Epoch 482/1000, Loss: 0.1752, Accuracy: 94.20%\n",
      "Epoch 483/1000, Loss: 0.1780, Accuracy: 94.71%\n",
      "Epoch 484/1000, Loss: 0.1845, Accuracy: 94.11%\n",
      "Epoch 485/1000, Loss: 0.1852, Accuracy: 93.99%\n",
      "Epoch 486/1000, Loss: 0.1810, Accuracy: 94.23%\n",
      "Epoch 487/1000, Loss: 0.1913, Accuracy: 93.33%\n",
      "Epoch 488/1000, Loss: 0.2069, Accuracy: 93.54%\n",
      "Epoch 489/1000, Loss: 0.1699, Accuracy: 94.35%\n",
      "Epoch 490/1000, Loss: 0.1847, Accuracy: 94.20%\n",
      "Epoch 491/1000, Loss: 0.1797, Accuracy: 94.23%\n",
      "Epoch 492/1000, Loss: 0.1919, Accuracy: 93.78%\n",
      "Epoch 493/1000, Loss: 0.1981, Accuracy: 93.99%\n",
      "Epoch 494/1000, Loss: 0.1745, Accuracy: 94.38%\n",
      "Epoch 495/1000, Loss: 0.1882, Accuracy: 94.05%\n",
      "Epoch 496/1000, Loss: 0.1955, Accuracy: 93.96%\n",
      "Epoch 497/1000, Loss: 0.1872, Accuracy: 94.08%\n",
      "Epoch 498/1000, Loss: 0.1966, Accuracy: 93.45%\n",
      "Epoch 499/1000, Loss: 0.1831, Accuracy: 93.96%\n",
      "Epoch 500/1000, Loss: 0.1811, Accuracy: 94.29%\n",
      "Epoch 501/1000, Loss: 0.1829, Accuracy: 94.23%\n",
      "Epoch 502/1000, Loss: 0.1720, Accuracy: 94.08%\n",
      "Epoch 503/1000, Loss: 0.1754, Accuracy: 94.11%\n",
      "Epoch 504/1000, Loss: 0.1848, Accuracy: 94.11%\n",
      "Epoch 505/1000, Loss: 0.1794, Accuracy: 93.90%\n",
      "Epoch 506/1000, Loss: 0.1852, Accuracy: 93.99%\n",
      "Epoch 507/1000, Loss: 0.1687, Accuracy: 94.26%\n",
      "Epoch 508/1000, Loss: 0.1838, Accuracy: 93.75%\n",
      "Epoch 509/1000, Loss: 0.1706, Accuracy: 94.53%\n",
      "Epoch 510/1000, Loss: 0.1710, Accuracy: 94.50%\n",
      "Epoch 511/1000, Loss: 0.1760, Accuracy: 94.44%\n",
      "Epoch 512/1000, Loss: 0.1918, Accuracy: 94.08%\n",
      "Epoch 513/1000, Loss: 0.1846, Accuracy: 93.96%\n",
      "Epoch 514/1000, Loss: 0.1692, Accuracy: 94.29%\n",
      "Epoch 515/1000, Loss: 0.1748, Accuracy: 94.41%\n",
      "Epoch 516/1000, Loss: 0.1750, Accuracy: 94.44%\n",
      "Epoch 517/1000, Loss: 0.1620, Accuracy: 94.32%\n",
      "Epoch 518/1000, Loss: 0.1606, Accuracy: 94.41%\n",
      "Epoch 519/1000, Loss: 0.1849, Accuracy: 94.05%\n",
      "Epoch 520/1000, Loss: 0.1862, Accuracy: 93.66%\n",
      "Epoch 521/1000, Loss: 0.1945, Accuracy: 93.84%\n",
      "Epoch 522/1000, Loss: 0.1762, Accuracy: 94.41%\n",
      "Epoch 523/1000, Loss: 0.1756, Accuracy: 94.38%\n",
      "Epoch 524/1000, Loss: 0.1787, Accuracy: 94.08%\n",
      "Epoch 525/1000, Loss: 0.1656, Accuracy: 94.38%\n",
      "Epoch 526/1000, Loss: 0.1771, Accuracy: 94.41%\n",
      "Epoch 527/1000, Loss: 0.1855, Accuracy: 94.17%\n",
      "Epoch 528/1000, Loss: 0.1837, Accuracy: 93.78%\n",
      "Epoch 529/1000, Loss: 0.1874, Accuracy: 94.08%\n",
      "Epoch 530/1000, Loss: 0.1731, Accuracy: 94.17%\n",
      "Epoch 531/1000, Loss: 0.1647, Accuracy: 94.62%\n",
      "Epoch 532/1000, Loss: 0.1799, Accuracy: 93.99%\n",
      "Epoch 533/1000, Loss: 0.1803, Accuracy: 94.38%\n",
      "Epoch 534/1000, Loss: 0.1702, Accuracy: 94.47%\n",
      "Epoch 535/1000, Loss: 0.1893, Accuracy: 93.57%\n",
      "Epoch 536/1000, Loss: 0.1810, Accuracy: 94.20%\n",
      "Epoch 537/1000, Loss: 0.1786, Accuracy: 94.32%\n",
      "Epoch 538/1000, Loss: 0.1764, Accuracy: 94.29%\n",
      "Epoch 539/1000, Loss: 0.1861, Accuracy: 94.41%\n",
      "Epoch 540/1000, Loss: 0.1742, Accuracy: 94.41%\n",
      "Epoch 541/1000, Loss: 0.1773, Accuracy: 94.05%\n",
      "Epoch 542/1000, Loss: 0.1693, Accuracy: 94.53%\n",
      "Epoch 543/1000, Loss: 0.1656, Accuracy: 94.56%\n",
      "Epoch 544/1000, Loss: 0.1661, Accuracy: 94.35%\n",
      "Epoch 545/1000, Loss: 0.1812, Accuracy: 93.96%\n",
      "Epoch 546/1000, Loss: 0.1694, Accuracy: 94.44%\n",
      "Epoch 547/1000, Loss: 0.1956, Accuracy: 93.84%\n",
      "Epoch 548/1000, Loss: 0.2083, Accuracy: 93.66%\n",
      "Epoch 549/1000, Loss: 0.1818, Accuracy: 93.75%\n",
      "Epoch 550/1000, Loss: 0.1845, Accuracy: 94.02%\n",
      "Epoch 551/1000, Loss: 0.1803, Accuracy: 94.20%\n",
      "Epoch 552/1000, Loss: 0.1585, Accuracy: 94.56%\n",
      "Epoch 553/1000, Loss: 0.1719, Accuracy: 94.32%\n",
      "Epoch 554/1000, Loss: 0.1836, Accuracy: 93.93%\n",
      "Epoch 555/1000, Loss: 0.1838, Accuracy: 93.84%\n",
      "Epoch 556/1000, Loss: 0.1842, Accuracy: 94.05%\n",
      "Epoch 557/1000, Loss: 0.1460, Accuracy: 95.01%\n",
      "Epoch 558/1000, Loss: 0.1869, Accuracy: 93.57%\n",
      "Epoch 559/1000, Loss: 0.1689, Accuracy: 94.56%\n",
      "Epoch 560/1000, Loss: 0.1839, Accuracy: 94.35%\n",
      "Epoch 561/1000, Loss: 0.1749, Accuracy: 94.32%\n",
      "Epoch 562/1000, Loss: 0.1768, Accuracy: 94.32%\n",
      "Epoch 563/1000, Loss: 0.1773, Accuracy: 94.44%\n",
      "Epoch 564/1000, Loss: 0.1597, Accuracy: 94.50%\n",
      "Epoch 565/1000, Loss: 0.1613, Accuracy: 94.53%\n",
      "Epoch 566/1000, Loss: 0.1803, Accuracy: 94.17%\n",
      "Epoch 567/1000, Loss: 0.1791, Accuracy: 94.20%\n",
      "Epoch 568/1000, Loss: 0.1711, Accuracy: 94.29%\n",
      "Epoch 569/1000, Loss: 0.1830, Accuracy: 94.14%\n",
      "Epoch 570/1000, Loss: 0.1746, Accuracy: 94.29%\n",
      "Epoch 571/1000, Loss: 0.1912, Accuracy: 94.02%\n",
      "Epoch 572/1000, Loss: 0.1773, Accuracy: 94.53%\n",
      "Epoch 573/1000, Loss: 0.1813, Accuracy: 93.93%\n",
      "Epoch 574/1000, Loss: 0.1620, Accuracy: 94.74%\n",
      "Epoch 575/1000, Loss: 0.1679, Accuracy: 94.14%\n",
      "Epoch 576/1000, Loss: 0.1681, Accuracy: 94.68%\n",
      "Epoch 577/1000, Loss: 0.1721, Accuracy: 94.41%\n",
      "Epoch 578/1000, Loss: 0.1757, Accuracy: 94.17%\n",
      "Epoch 579/1000, Loss: 0.1793, Accuracy: 93.93%\n",
      "Epoch 580/1000, Loss: 0.1662, Accuracy: 94.53%\n",
      "Epoch 581/1000, Loss: 0.1731, Accuracy: 94.17%\n",
      "Epoch 582/1000, Loss: 0.1803, Accuracy: 93.96%\n",
      "Epoch 583/1000, Loss: 0.1797, Accuracy: 93.93%\n",
      "Epoch 584/1000, Loss: 0.1891, Accuracy: 93.90%\n",
      "Epoch 585/1000, Loss: 0.1761, Accuracy: 94.05%\n",
      "Epoch 586/1000, Loss: 0.1824, Accuracy: 94.17%\n",
      "Epoch 587/1000, Loss: 0.1751, Accuracy: 94.62%\n",
      "Epoch 588/1000, Loss: 0.1699, Accuracy: 94.29%\n",
      "Epoch 589/1000, Loss: 0.1699, Accuracy: 94.74%\n",
      "Epoch 590/1000, Loss: 0.1745, Accuracy: 93.87%\n",
      "Epoch 591/1000, Loss: 0.1791, Accuracy: 94.38%\n",
      "Epoch 592/1000, Loss: 0.1682, Accuracy: 94.35%\n",
      "Epoch 593/1000, Loss: 0.1618, Accuracy: 95.13%\n",
      "Epoch 594/1000, Loss: 0.1736, Accuracy: 94.23%\n",
      "Epoch 595/1000, Loss: 0.1816, Accuracy: 93.84%\n",
      "Epoch 596/1000, Loss: 0.1788, Accuracy: 94.05%\n",
      "Epoch 597/1000, Loss: 0.1861, Accuracy: 94.38%\n",
      "Epoch 598/1000, Loss: 0.1663, Accuracy: 94.44%\n",
      "Epoch 599/1000, Loss: 0.1753, Accuracy: 94.20%\n",
      "Epoch 600/1000, Loss: 0.1872, Accuracy: 94.11%\n",
      "Epoch 601/1000, Loss: 0.1627, Accuracy: 94.80%\n",
      "Epoch 602/1000, Loss: 0.1635, Accuracy: 94.59%\n",
      "Epoch 603/1000, Loss: 0.1654, Accuracy: 94.68%\n",
      "Epoch 604/1000, Loss: 0.1565, Accuracy: 94.53%\n",
      "Epoch 605/1000, Loss: 0.1709, Accuracy: 94.38%\n",
      "Epoch 606/1000, Loss: 0.1575, Accuracy: 95.19%\n",
      "Epoch 607/1000, Loss: 0.1735, Accuracy: 94.29%\n",
      "Epoch 608/1000, Loss: 0.1645, Accuracy: 94.47%\n",
      "Epoch 609/1000, Loss: 0.1756, Accuracy: 94.41%\n",
      "Epoch 610/1000, Loss: 0.1702, Accuracy: 94.41%\n",
      "Epoch 611/1000, Loss: 0.1663, Accuracy: 94.77%\n",
      "Epoch 612/1000, Loss: 0.1742, Accuracy: 94.26%\n",
      "Epoch 613/1000, Loss: 0.1788, Accuracy: 94.11%\n",
      "Epoch 614/1000, Loss: 0.1672, Accuracy: 94.29%\n",
      "Epoch 615/1000, Loss: 0.1861, Accuracy: 93.99%\n",
      "Epoch 616/1000, Loss: 0.1799, Accuracy: 94.20%\n",
      "Epoch 617/1000, Loss: 0.1776, Accuracy: 94.26%\n",
      "Epoch 618/1000, Loss: 0.1838, Accuracy: 93.81%\n",
      "Epoch 619/1000, Loss: 0.1732, Accuracy: 94.32%\n",
      "Epoch 620/1000, Loss: 0.1725, Accuracy: 94.44%\n",
      "Epoch 621/1000, Loss: 0.1727, Accuracy: 94.59%\n",
      "Epoch 622/1000, Loss: 0.1681, Accuracy: 94.56%\n",
      "Epoch 623/1000, Loss: 0.1704, Accuracy: 94.41%\n",
      "Epoch 624/1000, Loss: 0.1630, Accuracy: 94.56%\n",
      "Epoch 625/1000, Loss: 0.1744, Accuracy: 94.50%\n",
      "Epoch 626/1000, Loss: 0.1609, Accuracy: 94.98%\n",
      "Epoch 627/1000, Loss: 0.1682, Accuracy: 94.62%\n",
      "Epoch 628/1000, Loss: 0.1672, Accuracy: 94.05%\n",
      "Epoch 629/1000, Loss: 0.1878, Accuracy: 93.90%\n",
      "Epoch 630/1000, Loss: 0.1894, Accuracy: 94.29%\n",
      "Epoch 631/1000, Loss: 0.1658, Accuracy: 94.44%\n",
      "Epoch 632/1000, Loss: 0.1732, Accuracy: 94.44%\n",
      "Epoch 633/1000, Loss: 0.1534, Accuracy: 94.80%\n",
      "Epoch 634/1000, Loss: 0.1689, Accuracy: 94.74%\n",
      "Epoch 635/1000, Loss: 0.2018, Accuracy: 93.60%\n",
      "Epoch 636/1000, Loss: 0.1731, Accuracy: 94.68%\n",
      "Epoch 637/1000, Loss: 0.1608, Accuracy: 94.89%\n",
      "Epoch 638/1000, Loss: 0.1817, Accuracy: 94.35%\n",
      "Epoch 639/1000, Loss: 0.1896, Accuracy: 94.17%\n",
      "Epoch 640/1000, Loss: 0.1682, Accuracy: 94.47%\n",
      "Epoch 641/1000, Loss: 0.1696, Accuracy: 94.59%\n",
      "Epoch 642/1000, Loss: 0.1511, Accuracy: 94.77%\n",
      "Epoch 643/1000, Loss: 0.1678, Accuracy: 94.53%\n",
      "Epoch 644/1000, Loss: 0.1615, Accuracy: 94.77%\n",
      "Epoch 645/1000, Loss: 0.1774, Accuracy: 93.99%\n",
      "Epoch 646/1000, Loss: 0.1671, Accuracy: 94.44%\n",
      "Epoch 647/1000, Loss: 0.1835, Accuracy: 94.02%\n",
      "Epoch 648/1000, Loss: 0.1590, Accuracy: 94.50%\n",
      "Epoch 649/1000, Loss: 0.1551, Accuracy: 95.16%\n",
      "Epoch 650/1000, Loss: 0.1610, Accuracy: 94.68%\n",
      "Epoch 651/1000, Loss: 0.1689, Accuracy: 94.02%\n",
      "Epoch 652/1000, Loss: 0.1783, Accuracy: 94.14%\n",
      "Epoch 653/1000, Loss: 0.1520, Accuracy: 94.83%\n",
      "Epoch 654/1000, Loss: 0.1739, Accuracy: 94.71%\n",
      "Epoch 655/1000, Loss: 0.1854, Accuracy: 93.99%\n",
      "Epoch 656/1000, Loss: 0.1570, Accuracy: 94.53%\n",
      "Epoch 657/1000, Loss: 0.1758, Accuracy: 94.47%\n",
      "Epoch 658/1000, Loss: 0.1530, Accuracy: 94.80%\n",
      "Epoch 659/1000, Loss: 0.1802, Accuracy: 94.26%\n",
      "Epoch 660/1000, Loss: 0.1435, Accuracy: 94.95%\n",
      "Epoch 661/1000, Loss: 0.1694, Accuracy: 94.71%\n",
      "Epoch 662/1000, Loss: 0.1741, Accuracy: 94.38%\n",
      "Epoch 663/1000, Loss: 0.1712, Accuracy: 94.59%\n",
      "Epoch 664/1000, Loss: 0.1739, Accuracy: 94.56%\n",
      "Epoch 665/1000, Loss: 0.1643, Accuracy: 94.65%\n",
      "Epoch 666/1000, Loss: 0.1610, Accuracy: 94.86%\n",
      "Epoch 667/1000, Loss: 0.1688, Accuracy: 94.68%\n",
      "Epoch 668/1000, Loss: 0.1660, Accuracy: 94.83%\n",
      "Epoch 669/1000, Loss: 0.1635, Accuracy: 94.47%\n",
      "Epoch 670/1000, Loss: 0.1509, Accuracy: 94.98%\n",
      "Epoch 671/1000, Loss: 0.1712, Accuracy: 94.05%\n",
      "Epoch 672/1000, Loss: 0.1559, Accuracy: 94.56%\n",
      "Epoch 673/1000, Loss: 0.1621, Accuracy: 94.62%\n",
      "Epoch 674/1000, Loss: 0.1632, Accuracy: 94.47%\n",
      "Epoch 675/1000, Loss: 0.1597, Accuracy: 94.92%\n",
      "Epoch 676/1000, Loss: 0.1840, Accuracy: 94.59%\n",
      "Epoch 677/1000, Loss: 0.1604, Accuracy: 94.35%\n",
      "Epoch 678/1000, Loss: 0.1568, Accuracy: 94.65%\n",
      "Epoch 679/1000, Loss: 0.1732, Accuracy: 94.95%\n",
      "Epoch 680/1000, Loss: 0.1606, Accuracy: 94.74%\n",
      "Epoch 681/1000, Loss: 0.1663, Accuracy: 94.47%\n",
      "Epoch 682/1000, Loss: 0.1811, Accuracy: 94.05%\n",
      "Epoch 683/1000, Loss: 0.1756, Accuracy: 94.17%\n",
      "Epoch 684/1000, Loss: 0.1610, Accuracy: 94.95%\n",
      "Epoch 685/1000, Loss: 0.1776, Accuracy: 94.47%\n",
      "Epoch 686/1000, Loss: 0.1883, Accuracy: 94.08%\n",
      "Epoch 687/1000, Loss: 0.1742, Accuracy: 94.59%\n",
      "Epoch 688/1000, Loss: 0.1569, Accuracy: 95.04%\n",
      "Epoch 689/1000, Loss: 0.1748, Accuracy: 94.14%\n",
      "Epoch 690/1000, Loss: 0.1532, Accuracy: 95.04%\n",
      "Epoch 691/1000, Loss: 0.1684, Accuracy: 94.32%\n",
      "Epoch 692/1000, Loss: 0.1741, Accuracy: 94.65%\n",
      "Epoch 693/1000, Loss: 0.1795, Accuracy: 94.32%\n",
      "Epoch 694/1000, Loss: 0.1687, Accuracy: 94.20%\n",
      "Epoch 695/1000, Loss: 0.1628, Accuracy: 94.77%\n",
      "Epoch 696/1000, Loss: 0.1643, Accuracy: 94.59%\n",
      "Epoch 697/1000, Loss: 0.1459, Accuracy: 95.07%\n",
      "Epoch 698/1000, Loss: 0.1643, Accuracy: 94.62%\n",
      "Epoch 699/1000, Loss: 0.1502, Accuracy: 95.10%\n",
      "Epoch 700/1000, Loss: 0.1646, Accuracy: 94.47%\n",
      "Epoch 701/1000, Loss: 0.1894, Accuracy: 94.08%\n",
      "Epoch 702/1000, Loss: 0.2028, Accuracy: 93.48%\n",
      "Epoch 703/1000, Loss: 0.1781, Accuracy: 94.47%\n",
      "Epoch 704/1000, Loss: 0.1694, Accuracy: 94.38%\n",
      "Epoch 705/1000, Loss: 0.1555, Accuracy: 94.83%\n",
      "Epoch 706/1000, Loss: 0.1743, Accuracy: 93.93%\n",
      "Epoch 707/1000, Loss: 0.1726, Accuracy: 94.77%\n",
      "Epoch 708/1000, Loss: 0.1640, Accuracy: 94.56%\n",
      "Epoch 709/1000, Loss: 0.1552, Accuracy: 94.98%\n",
      "Epoch 710/1000, Loss: 0.1671, Accuracy: 94.80%\n",
      "Epoch 711/1000, Loss: 0.1666, Accuracy: 94.74%\n",
      "Epoch 712/1000, Loss: 0.1560, Accuracy: 94.71%\n",
      "Epoch 713/1000, Loss: 0.1803, Accuracy: 94.32%\n",
      "Epoch 714/1000, Loss: 0.1908, Accuracy: 94.17%\n",
      "Epoch 715/1000, Loss: 0.1623, Accuracy: 94.74%\n",
      "Epoch 716/1000, Loss: 0.1601, Accuracy: 94.47%\n",
      "Epoch 717/1000, Loss: 0.1515, Accuracy: 95.13%\n",
      "Epoch 718/1000, Loss: 0.1869, Accuracy: 94.53%\n",
      "Epoch 719/1000, Loss: 0.1707, Accuracy: 94.26%\n",
      "Epoch 720/1000, Loss: 0.1598, Accuracy: 94.86%\n",
      "Epoch 721/1000, Loss: 0.1708, Accuracy: 94.35%\n",
      "Epoch 722/1000, Loss: 0.1624, Accuracy: 94.98%\n",
      "Epoch 723/1000, Loss: 0.1658, Accuracy: 94.74%\n",
      "Epoch 724/1000, Loss: 0.1552, Accuracy: 94.98%\n",
      "Epoch 725/1000, Loss: 0.1632, Accuracy: 94.53%\n",
      "Epoch 726/1000, Loss: 0.1731, Accuracy: 94.44%\n",
      "Epoch 727/1000, Loss: 0.1843, Accuracy: 94.29%\n",
      "Epoch 728/1000, Loss: 0.1674, Accuracy: 94.59%\n",
      "Epoch 729/1000, Loss: 0.1618, Accuracy: 95.13%\n",
      "Epoch 730/1000, Loss: 0.1688, Accuracy: 94.38%\n",
      "Epoch 731/1000, Loss: 0.1610, Accuracy: 94.89%\n",
      "Epoch 732/1000, Loss: 0.1808, Accuracy: 94.35%\n",
      "Epoch 733/1000, Loss: 0.1568, Accuracy: 94.83%\n",
      "Epoch 734/1000, Loss: 0.1650, Accuracy: 94.77%\n",
      "Epoch 735/1000, Loss: 0.1559, Accuracy: 95.22%\n",
      "Epoch 736/1000, Loss: 0.1705, Accuracy: 94.62%\n",
      "Epoch 737/1000, Loss: 0.1835, Accuracy: 94.41%\n",
      "Epoch 738/1000, Loss: 0.1619, Accuracy: 94.62%\n",
      "Epoch 739/1000, Loss: 0.1988, Accuracy: 93.93%\n",
      "Epoch 740/1000, Loss: 0.1812, Accuracy: 94.26%\n",
      "Epoch 741/1000, Loss: 0.1567, Accuracy: 94.68%\n",
      "Epoch 742/1000, Loss: 0.1853, Accuracy: 94.26%\n",
      "Epoch 743/1000, Loss: 0.1653, Accuracy: 94.68%\n",
      "Epoch 744/1000, Loss: 0.1713, Accuracy: 94.47%\n",
      "Epoch 745/1000, Loss: 0.1738, Accuracy: 94.32%\n",
      "Epoch 746/1000, Loss: 0.1678, Accuracy: 94.65%\n",
      "Epoch 747/1000, Loss: 0.1674, Accuracy: 94.74%\n",
      "Epoch 748/1000, Loss: 0.1564, Accuracy: 94.80%\n",
      "Epoch 749/1000, Loss: 0.1907, Accuracy: 94.32%\n",
      "Epoch 750/1000, Loss: 0.1587, Accuracy: 94.83%\n",
      "Epoch 751/1000, Loss: 0.1867, Accuracy: 94.08%\n",
      "Epoch 752/1000, Loss: 0.1515, Accuracy: 95.16%\n",
      "Epoch 753/1000, Loss: 0.1798, Accuracy: 94.26%\n",
      "Epoch 754/1000, Loss: 0.1630, Accuracy: 94.65%\n",
      "Epoch 755/1000, Loss: 0.1635, Accuracy: 94.56%\n",
      "Epoch 756/1000, Loss: 0.1445, Accuracy: 95.22%\n",
      "Epoch 757/1000, Loss: 0.1585, Accuracy: 94.65%\n",
      "Epoch 758/1000, Loss: 0.1624, Accuracy: 94.89%\n",
      "Epoch 759/1000, Loss: 0.1576, Accuracy: 94.92%\n",
      "Epoch 760/1000, Loss: 0.1582, Accuracy: 94.59%\n",
      "Epoch 761/1000, Loss: 0.1642, Accuracy: 94.47%\n",
      "Epoch 762/1000, Loss: 0.1601, Accuracy: 94.89%\n",
      "Epoch 763/1000, Loss: 0.1819, Accuracy: 94.68%\n",
      "Epoch 764/1000, Loss: 0.1500, Accuracy: 95.01%\n",
      "Epoch 765/1000, Loss: 0.1573, Accuracy: 94.50%\n",
      "Epoch 766/1000, Loss: 0.1651, Accuracy: 95.07%\n",
      "Epoch 767/1000, Loss: 0.1676, Accuracy: 94.56%\n",
      "Epoch 768/1000, Loss: 0.1528, Accuracy: 95.10%\n",
      "Epoch 769/1000, Loss: 0.1641, Accuracy: 94.65%\n",
      "Epoch 770/1000, Loss: 0.1521, Accuracy: 95.13%\n",
      "Epoch 771/1000, Loss: 0.1736, Accuracy: 94.26%\n",
      "Epoch 772/1000, Loss: 0.1580, Accuracy: 94.95%\n",
      "Epoch 773/1000, Loss: 0.1718, Accuracy: 94.89%\n",
      "Epoch 774/1000, Loss: 0.1730, Accuracy: 94.56%\n",
      "Epoch 775/1000, Loss: 0.1749, Accuracy: 94.08%\n",
      "Epoch 776/1000, Loss: 0.1492, Accuracy: 94.92%\n",
      "Epoch 777/1000, Loss: 0.1726, Accuracy: 94.56%\n",
      "Epoch 778/1000, Loss: 0.1572, Accuracy: 94.89%\n",
      "Epoch 779/1000, Loss: 0.1745, Accuracy: 94.38%\n",
      "Epoch 780/1000, Loss: 0.1607, Accuracy: 94.59%\n",
      "Epoch 781/1000, Loss: 0.1490, Accuracy: 95.13%\n",
      "Epoch 782/1000, Loss: 0.1701, Accuracy: 94.32%\n",
      "Epoch 783/1000, Loss: 0.1573, Accuracy: 94.74%\n",
      "Epoch 784/1000, Loss: 0.1719, Accuracy: 94.65%\n",
      "Epoch 785/1000, Loss: 0.1738, Accuracy: 94.35%\n",
      "Epoch 786/1000, Loss: 0.1844, Accuracy: 94.02%\n",
      "Epoch 787/1000, Loss: 0.1694, Accuracy: 94.29%\n",
      "Epoch 788/1000, Loss: 0.1696, Accuracy: 94.38%\n",
      "Epoch 789/1000, Loss: 0.1858, Accuracy: 94.29%\n",
      "Epoch 790/1000, Loss: 0.1667, Accuracy: 94.44%\n",
      "Epoch 791/1000, Loss: 0.1587, Accuracy: 94.92%\n",
      "Epoch 792/1000, Loss: 0.1310, Accuracy: 95.52%\n",
      "Epoch 793/1000, Loss: 0.1702, Accuracy: 94.53%\n",
      "Epoch 794/1000, Loss: 0.1690, Accuracy: 94.65%\n",
      "Epoch 795/1000, Loss: 0.1601, Accuracy: 94.68%\n",
      "Epoch 796/1000, Loss: 0.1545, Accuracy: 94.68%\n",
      "Epoch 797/1000, Loss: 0.1636, Accuracy: 94.98%\n",
      "Epoch 798/1000, Loss: 0.1852, Accuracy: 94.41%\n",
      "Epoch 799/1000, Loss: 0.1717, Accuracy: 94.29%\n",
      "Epoch 800/1000, Loss: 0.1618, Accuracy: 94.74%\n",
      "Epoch 801/1000, Loss: 0.1681, Accuracy: 95.01%\n",
      "Epoch 802/1000, Loss: 0.1849, Accuracy: 94.20%\n",
      "Epoch 803/1000, Loss: 0.1676, Accuracy: 94.68%\n",
      "Epoch 804/1000, Loss: 0.1790, Accuracy: 94.32%\n",
      "Epoch 805/1000, Loss: 0.1536, Accuracy: 94.86%\n",
      "Epoch 806/1000, Loss: 0.1590, Accuracy: 94.80%\n",
      "Epoch 807/1000, Loss: 0.1538, Accuracy: 94.89%\n",
      "Epoch 808/1000, Loss: 0.1634, Accuracy: 94.71%\n",
      "Epoch 809/1000, Loss: 0.1474, Accuracy: 94.80%\n",
      "Epoch 810/1000, Loss: 0.1552, Accuracy: 95.04%\n",
      "Epoch 811/1000, Loss: 0.1764, Accuracy: 94.38%\n",
      "Epoch 812/1000, Loss: 0.1676, Accuracy: 94.71%\n",
      "Epoch 813/1000, Loss: 0.1650, Accuracy: 94.62%\n",
      "Epoch 814/1000, Loss: 0.1575, Accuracy: 94.65%\n",
      "Epoch 815/1000, Loss: 0.1657, Accuracy: 94.56%\n",
      "Epoch 816/1000, Loss: 0.1638, Accuracy: 94.68%\n",
      "Epoch 817/1000, Loss: 0.1586, Accuracy: 94.65%\n",
      "Epoch 818/1000, Loss: 0.1620, Accuracy: 94.62%\n",
      "Epoch 819/1000, Loss: 0.1669, Accuracy: 94.41%\n",
      "Epoch 820/1000, Loss: 0.1702, Accuracy: 94.62%\n",
      "Epoch 821/1000, Loss: 0.1780, Accuracy: 93.99%\n",
      "Epoch 822/1000, Loss: 0.1670, Accuracy: 94.65%\n",
      "Epoch 823/1000, Loss: 0.1594, Accuracy: 94.86%\n",
      "Epoch 824/1000, Loss: 0.1643, Accuracy: 94.26%\n",
      "Epoch 825/1000, Loss: 0.1486, Accuracy: 94.74%\n",
      "Epoch 826/1000, Loss: 0.1481, Accuracy: 95.10%\n",
      "Epoch 827/1000, Loss: 0.1706, Accuracy: 94.83%\n",
      "Epoch 828/1000, Loss: 0.1600, Accuracy: 94.77%\n",
      "Epoch 829/1000, Loss: 0.1717, Accuracy: 94.56%\n",
      "Epoch 830/1000, Loss: 0.1568, Accuracy: 94.83%\n",
      "Epoch 831/1000, Loss: 0.1681, Accuracy: 94.56%\n",
      "Epoch 832/1000, Loss: 0.1650, Accuracy: 94.32%\n",
      "Epoch 833/1000, Loss: 0.1524, Accuracy: 95.07%\n",
      "Epoch 834/1000, Loss: 0.1545, Accuracy: 95.01%\n",
      "Epoch 835/1000, Loss: 0.1625, Accuracy: 94.74%\n",
      "Epoch 836/1000, Loss: 0.1412, Accuracy: 95.10%\n",
      "Epoch 837/1000, Loss: 0.1506, Accuracy: 94.80%\n",
      "Epoch 838/1000, Loss: 0.1720, Accuracy: 94.71%\n",
      "Epoch 839/1000, Loss: 0.1632, Accuracy: 95.10%\n",
      "Epoch 840/1000, Loss: 0.1823, Accuracy: 94.29%\n",
      "Epoch 841/1000, Loss: 0.1685, Accuracy: 94.65%\n",
      "Epoch 842/1000, Loss: 0.1448, Accuracy: 95.07%\n",
      "Epoch 843/1000, Loss: 0.1561, Accuracy: 94.98%\n",
      "Epoch 844/1000, Loss: 0.1579, Accuracy: 94.89%\n",
      "Epoch 845/1000, Loss: 0.1609, Accuracy: 94.89%\n",
      "Epoch 846/1000, Loss: 0.1678, Accuracy: 94.50%\n",
      "Epoch 847/1000, Loss: 0.1581, Accuracy: 94.35%\n",
      "Epoch 848/1000, Loss: 0.1578, Accuracy: 94.71%\n",
      "Epoch 849/1000, Loss: 0.1686, Accuracy: 94.38%\n",
      "Epoch 850/1000, Loss: 0.1729, Accuracy: 94.29%\n",
      "Epoch 851/1000, Loss: 0.1565, Accuracy: 95.04%\n",
      "Epoch 852/1000, Loss: 0.1597, Accuracy: 95.19%\n",
      "Epoch 853/1000, Loss: 0.1586, Accuracy: 94.50%\n",
      "Epoch 854/1000, Loss: 0.1781, Accuracy: 94.26%\n",
      "Epoch 855/1000, Loss: 0.1636, Accuracy: 94.62%\n",
      "Epoch 856/1000, Loss: 0.1505, Accuracy: 94.83%\n",
      "Epoch 857/1000, Loss: 0.1660, Accuracy: 95.01%\n",
      "Epoch 858/1000, Loss: 0.1634, Accuracy: 94.23%\n",
      "Epoch 859/1000, Loss: 0.1685, Accuracy: 94.59%\n",
      "Epoch 860/1000, Loss: 0.1606, Accuracy: 94.68%\n",
      "Epoch 861/1000, Loss: 0.1595, Accuracy: 95.31%\n",
      "Epoch 862/1000, Loss: 0.1713, Accuracy: 94.59%\n",
      "Epoch 863/1000, Loss: 0.1596, Accuracy: 94.44%\n",
      "Epoch 864/1000, Loss: 0.1700, Accuracy: 94.41%\n",
      "Epoch 865/1000, Loss: 0.1636, Accuracy: 94.80%\n",
      "Epoch 866/1000, Loss: 0.1613, Accuracy: 94.65%\n",
      "Epoch 867/1000, Loss: 0.1506, Accuracy: 94.92%\n",
      "Epoch 868/1000, Loss: 0.1738, Accuracy: 94.59%\n",
      "Epoch 869/1000, Loss: 0.1524, Accuracy: 95.04%\n",
      "Epoch 870/1000, Loss: 0.1545, Accuracy: 94.59%\n",
      "Epoch 871/1000, Loss: 0.1616, Accuracy: 94.59%\n",
      "Epoch 872/1000, Loss: 0.1452, Accuracy: 95.04%\n",
      "Epoch 873/1000, Loss: 0.1638, Accuracy: 94.65%\n",
      "Epoch 874/1000, Loss: 0.1769, Accuracy: 94.47%\n",
      "Epoch 875/1000, Loss: 0.1519, Accuracy: 95.01%\n",
      "Epoch 876/1000, Loss: 0.1468, Accuracy: 95.01%\n",
      "Epoch 877/1000, Loss: 0.1544, Accuracy: 95.13%\n",
      "Epoch 878/1000, Loss: 0.1511, Accuracy: 95.04%\n",
      "Epoch 879/1000, Loss: 0.1587, Accuracy: 94.77%\n",
      "Epoch 880/1000, Loss: 0.1660, Accuracy: 94.71%\n",
      "Epoch 881/1000, Loss: 0.1528, Accuracy: 95.25%\n",
      "Epoch 882/1000, Loss: 0.1581, Accuracy: 94.86%\n",
      "Epoch 883/1000, Loss: 0.1783, Accuracy: 94.65%\n",
      "Epoch 884/1000, Loss: 0.1556, Accuracy: 94.83%\n",
      "Epoch 885/1000, Loss: 0.1567, Accuracy: 94.89%\n",
      "Epoch 886/1000, Loss: 0.1450, Accuracy: 95.07%\n",
      "Epoch 887/1000, Loss: 0.1535, Accuracy: 95.13%\n",
      "Epoch 888/1000, Loss: 0.1541, Accuracy: 95.16%\n",
      "Epoch 889/1000, Loss: 0.1718, Accuracy: 94.74%\n",
      "Epoch 890/1000, Loss: 0.1700, Accuracy: 94.38%\n",
      "Epoch 891/1000, Loss: 0.1625, Accuracy: 94.65%\n",
      "Epoch 892/1000, Loss: 0.1654, Accuracy: 94.62%\n",
      "Epoch 893/1000, Loss: 0.1585, Accuracy: 94.92%\n",
      "Epoch 894/1000, Loss: 0.1435, Accuracy: 95.13%\n",
      "Epoch 895/1000, Loss: 0.1698, Accuracy: 94.68%\n",
      "Epoch 896/1000, Loss: 0.1655, Accuracy: 94.35%\n",
      "Epoch 897/1000, Loss: 0.1498, Accuracy: 94.95%\n",
      "Epoch 898/1000, Loss: 0.1490, Accuracy: 95.10%\n",
      "Epoch 899/1000, Loss: 0.1603, Accuracy: 94.50%\n",
      "Epoch 900/1000, Loss: 0.1612, Accuracy: 94.86%\n",
      "Epoch 901/1000, Loss: 0.1427, Accuracy: 95.22%\n",
      "Epoch 902/1000, Loss: 0.1551, Accuracy: 94.77%\n",
      "Epoch 903/1000, Loss: 0.1596, Accuracy: 94.92%\n",
      "Epoch 904/1000, Loss: 0.1539, Accuracy: 94.95%\n",
      "Epoch 905/1000, Loss: 0.1567, Accuracy: 95.10%\n",
      "Epoch 906/1000, Loss: 0.1556, Accuracy: 94.89%\n",
      "Epoch 907/1000, Loss: 0.1518, Accuracy: 94.95%\n",
      "Epoch 908/1000, Loss: 0.1628, Accuracy: 94.95%\n",
      "Epoch 909/1000, Loss: 0.1568, Accuracy: 94.86%\n",
      "Epoch 910/1000, Loss: 0.1690, Accuracy: 94.50%\n",
      "Epoch 911/1000, Loss: 0.1620, Accuracy: 94.68%\n",
      "Epoch 912/1000, Loss: 0.1496, Accuracy: 95.49%\n",
      "Epoch 913/1000, Loss: 0.1585, Accuracy: 95.16%\n",
      "Epoch 914/1000, Loss: 0.1626, Accuracy: 94.71%\n",
      "Epoch 915/1000, Loss: 0.1786, Accuracy: 94.23%\n",
      "Epoch 916/1000, Loss: 0.1723, Accuracy: 94.44%\n",
      "Epoch 917/1000, Loss: 0.1609, Accuracy: 94.92%\n",
      "Epoch 918/1000, Loss: 0.1595, Accuracy: 94.74%\n",
      "Epoch 919/1000, Loss: 0.1634, Accuracy: 94.47%\n",
      "Epoch 920/1000, Loss: 0.1727, Accuracy: 94.59%\n",
      "Epoch 921/1000, Loss: 0.1566, Accuracy: 95.16%\n",
      "Epoch 922/1000, Loss: 0.1554, Accuracy: 94.86%\n",
      "Epoch 923/1000, Loss: 0.1549, Accuracy: 94.77%\n",
      "Epoch 924/1000, Loss: 0.1464, Accuracy: 95.46%\n",
      "Epoch 925/1000, Loss: 0.1683, Accuracy: 94.56%\n",
      "Epoch 926/1000, Loss: 0.1561, Accuracy: 95.01%\n",
      "Epoch 927/1000, Loss: 0.1600, Accuracy: 94.83%\n",
      "Epoch 928/1000, Loss: 0.1604, Accuracy: 94.74%\n",
      "Epoch 929/1000, Loss: 0.1673, Accuracy: 94.74%\n",
      "Epoch 930/1000, Loss: 0.1543, Accuracy: 94.71%\n",
      "Epoch 931/1000, Loss: 0.1597, Accuracy: 94.71%\n",
      "Epoch 932/1000, Loss: 0.1561, Accuracy: 95.16%\n",
      "Epoch 933/1000, Loss: 0.1580, Accuracy: 95.13%\n",
      "Epoch 934/1000, Loss: 0.1709, Accuracy: 94.95%\n",
      "Epoch 935/1000, Loss: 0.1463, Accuracy: 94.92%\n",
      "Epoch 936/1000, Loss: 0.1668, Accuracy: 94.71%\n",
      "Epoch 937/1000, Loss: 0.1682, Accuracy: 94.95%\n",
      "Epoch 938/1000, Loss: 0.1582, Accuracy: 94.68%\n",
      "Epoch 939/1000, Loss: 0.1494, Accuracy: 95.10%\n",
      "Epoch 940/1000, Loss: 0.1742, Accuracy: 94.50%\n",
      "Epoch 941/1000, Loss: 0.1808, Accuracy: 94.26%\n",
      "Epoch 942/1000, Loss: 0.1584, Accuracy: 94.74%\n",
      "Epoch 943/1000, Loss: 0.1790, Accuracy: 94.35%\n",
      "Epoch 944/1000, Loss: 0.1486, Accuracy: 94.92%\n",
      "Epoch 945/1000, Loss: 0.1378, Accuracy: 95.28%\n",
      "Epoch 946/1000, Loss: 0.1502, Accuracy: 95.31%\n",
      "Epoch 947/1000, Loss: 0.1683, Accuracy: 94.65%\n",
      "Epoch 948/1000, Loss: 0.1533, Accuracy: 94.92%\n",
      "Epoch 949/1000, Loss: 0.1550, Accuracy: 94.92%\n",
      "Epoch 950/1000, Loss: 0.1510, Accuracy: 94.92%\n",
      "Epoch 951/1000, Loss: 0.1628, Accuracy: 94.77%\n",
      "Epoch 952/1000, Loss: 0.1647, Accuracy: 94.47%\n",
      "Epoch 953/1000, Loss: 0.1634, Accuracy: 94.83%\n",
      "Epoch 954/1000, Loss: 0.1603, Accuracy: 94.86%\n",
      "Epoch 955/1000, Loss: 0.1544, Accuracy: 94.71%\n",
      "Epoch 956/1000, Loss: 0.1466, Accuracy: 95.28%\n",
      "Epoch 957/1000, Loss: 0.1384, Accuracy: 95.25%\n",
      "Epoch 958/1000, Loss: 0.1679, Accuracy: 94.71%\n",
      "Epoch 959/1000, Loss: 0.1595, Accuracy: 94.68%\n",
      "Epoch 960/1000, Loss: 0.1520, Accuracy: 95.37%\n",
      "Epoch 961/1000, Loss: 0.1628, Accuracy: 94.77%\n",
      "Epoch 962/1000, Loss: 0.1754, Accuracy: 94.02%\n",
      "Epoch 963/1000, Loss: 0.1555, Accuracy: 95.01%\n",
      "Epoch 964/1000, Loss: 0.1545, Accuracy: 95.10%\n",
      "Epoch 965/1000, Loss: 0.1433, Accuracy: 95.28%\n",
      "Epoch 966/1000, Loss: 0.1534, Accuracy: 95.07%\n",
      "Epoch 967/1000, Loss: 0.1342, Accuracy: 95.22%\n",
      "Epoch 968/1000, Loss: 0.1770, Accuracy: 94.20%\n",
      "Epoch 969/1000, Loss: 0.1576, Accuracy: 95.04%\n",
      "Epoch 970/1000, Loss: 0.1628, Accuracy: 94.62%\n",
      "Epoch 971/1000, Loss: 0.1663, Accuracy: 94.56%\n",
      "Epoch 972/1000, Loss: 0.1579, Accuracy: 95.10%\n",
      "Epoch 973/1000, Loss: 0.1563, Accuracy: 95.34%\n",
      "Epoch 974/1000, Loss: 0.1537, Accuracy: 94.80%\n",
      "Epoch 975/1000, Loss: 0.1704, Accuracy: 94.44%\n",
      "Epoch 976/1000, Loss: 0.1568, Accuracy: 94.89%\n",
      "Epoch 977/1000, Loss: 0.1558, Accuracy: 94.95%\n",
      "Epoch 978/1000, Loss: 0.1571, Accuracy: 94.86%\n",
      "Epoch 979/1000, Loss: 0.1542, Accuracy: 94.98%\n",
      "Epoch 980/1000, Loss: 0.1723, Accuracy: 94.38%\n",
      "Epoch 981/1000, Loss: 0.1608, Accuracy: 94.56%\n",
      "Epoch 982/1000, Loss: 0.1490, Accuracy: 94.95%\n",
      "Epoch 983/1000, Loss: 0.1529, Accuracy: 95.19%\n",
      "Epoch 984/1000, Loss: 0.1553, Accuracy: 95.01%\n",
      "Epoch 985/1000, Loss: 0.1710, Accuracy: 94.80%\n",
      "Epoch 986/1000, Loss: 0.1510, Accuracy: 95.19%\n",
      "Epoch 987/1000, Loss: 0.1499, Accuracy: 95.07%\n",
      "Epoch 988/1000, Loss: 0.1631, Accuracy: 94.83%\n",
      "Epoch 989/1000, Loss: 0.1601, Accuracy: 94.86%\n",
      "Epoch 990/1000, Loss: 0.1563, Accuracy: 94.68%\n",
      "Epoch 991/1000, Loss: 0.1540, Accuracy: 95.28%\n",
      "Epoch 992/1000, Loss: 0.1495, Accuracy: 95.28%\n",
      "Epoch 993/1000, Loss: 0.1519, Accuracy: 94.86%\n",
      "Epoch 994/1000, Loss: 0.1658, Accuracy: 94.77%\n",
      "Epoch 995/1000, Loss: 0.1529, Accuracy: 95.13%\n",
      "Epoch 996/1000, Loss: 0.1679, Accuracy: 94.62%\n",
      "Epoch 997/1000, Loss: 0.1686, Accuracy: 94.89%\n",
      "Epoch 998/1000, Loss: 0.1658, Accuracy: 95.16%\n",
      "Epoch 999/1000, Loss: 0.1506, Accuracy: 94.86%\n",
      "Epoch 1000/1000, Loss: 0.1586, Accuracy: 94.47%\n",
      "Test Accuracy: 95.19%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, num_epochs=1000)\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_kernel",
   "language": "python",
   "name": "myproject_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
